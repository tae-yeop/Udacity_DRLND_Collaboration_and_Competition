{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "## 0. Learning Algorithm\n",
    "---\n",
    "To solve the Unity tennis problem, I choose [MADDPG algorithm](http://arxiv.org/abs/1706.02275)(Lowe et al., Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algorithm**\n",
    "\n",
    "MADDPG(Multi-Agent Deep Deterministic Policy Gradient) Algorithm extrapolates the DDPG algorithm to the multi-agent case. This general purpose algorithm is applicable to cooperative-competitive environment like this tennis problem. \n",
    "\n",
    "This algorithm takes the centralized training with decentralized execution. So each agent uses other agent's policies at training time, but this information is not used in test time. To put it concretely, critic network takes not only its own observation and action but also other agent's observations and actions. But when the agents try to choose actions at test time, they will use their own observation only.\n",
    "\n",
    "Full MADDPG training algorithm is presented as follows. Note that local actor network(not target actor network)is used to produce particular one agent's action $a_i$ when updating actor network. But the other agents' actions are just the actions sampled from replay buffer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<figure>\n",
    "  <img src = \"./pic/maddpg.png\" width = 80% style = \"border: thin silver solid; padding: 10px\">\n",
    "      <figcaption style = \"text-align: center; font-style: italic\">Fig 1. - MADDPG Algorithm. (Lowe et al., Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments, 13.)</figcaption>\n",
    "</figure> \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like DDPG algorithm, I use replay buffer and Ornstein-Uhlenbeck noise process. The replay buffer is shared through all agents but it stores other agent's information for the centralized action-value function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Architecture**\n",
    "\n",
    "Based on the experiment details from [Lowe et al.](http://arxiv.org/abs/1706.02275) , I used the similar shallow and small networks. Both actor and critic networks have 3 fully connected layers. These layers are consist of an input layer and 2 hidden layers.  Since the state size is 24, So the input size of the actor network is 24. And the input size of critic network is 52, because It takes all the other agent' observations and actions. In this project, there are 2 agents, so 2*(state_size+action_size) = 54."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Actor(\n",
    "  (bn1): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (fc1): Linear(in_features=24, out_features=96, bias=True)\n",
    "  (bn2): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (fc2): Linear(in_features=96, out_features=96, bias=True)\n",
    "  (bn3): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (fc3): Linear(in_features=96, out_features=2, bias=True)\n",
    ")\n",
    "\n",
    "\n",
    "Critic(\n",
    "  (fc1): Linear(in_features=52, out_features=96, bias=True)\n",
    "  (fc2): Linear(in_features=96, out_features=96, bias=True)\n",
    "  (fc3): Linear(in_features=96, out_features=1, bias=True)\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Packages and Environment\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as I\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "%aimport ddpg, maddpg\n",
    "\n",
    "from maddpg import MADDPG\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "env = UnityEnvironment(file_name=\"data/Tennis_Windows_x86_64/Tennis.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training\n",
    "---\n",
    "### 1. Hyperparameters\n",
    "\n",
    "You need to set all the hyperparameters to run the training code or to see the actual agents's behaviours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'model_18'\n",
    "model_save_path = 'model/'\n",
    "params = {}\n",
    "# Model Hyperparameters\n",
    "params['BUFFER_SIZE'] = int(1e6)\n",
    "params['BATCH_SIZE'] = 256\n",
    "params['GAMMA'] = 0.95\n",
    "params['TAU'] = 1e-2\n",
    "params['LR_ACTOR'] = 1e-3\n",
    "params['LR_CRITIC'] = 1e-3\n",
    "params['WEIGHT_DECAY'] = 0.0001\n",
    "params['TRAIN_ITER'] = 15\n",
    "params['TRAIN_FREQ'] = 10\n",
    "params['FC1'] = 96\n",
    "params['FC2'] = 96\n",
    "params['SEED'] = 0\n",
    "params['CLIPPING'] = False\n",
    "# Noise parameters\n",
    "params['SIGMA'] = 0.15\n",
    "params['THETA'] = 0.15\n",
    "params['SCALE'] = 0.9\n",
    "\n",
    "\n",
    "# model save frequency\n",
    "CHECKPOINT_FREQ = 3\n",
    "# score printing frequency\n",
    "PRINT_EVERY = 50\n",
    "GOAL_AVG_SCORE = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Set up\n",
    "\n",
    "Check if there is previous saved model. If there are checkpoints, then load the checkpoints and scores information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up(model_name, params):\n",
    "    \"\"\"\n",
    "    set up for traning\n",
    "    If the model and its score already exist, load the model and score\n",
    "    \n",
    "    Returns\n",
    "    ======\n",
    "    scores (list) : score history \n",
    "    score_deque (deque) : score window \n",
    "    current_episode (int) : current episode number \n",
    "    multiAgent (MultiAgent)\n",
    "    \"\"\"\n",
    "    target_path = model_save_path+model_name\n",
    "    # If the model already exists\n",
    "    if os.path.exists(target_path):\n",
    "        # Check it there are checkpoint files\n",
    "        if not glob.glob(target_path+'/*.pth'):\n",
    "            raise Exception('Previous model file doesnt exists')\n",
    "        # Get params from the previous saved params.json\n",
    "        with open(target_path+'/params.json', 'r') as f:\n",
    "            # previous param dict\n",
    "            prev_params = json.load(f)\n",
    "        # Get previous score data    \n",
    "        with open(target_path+'/scores.json', 'r') as f:\n",
    "            prev_score_data = json.load(f)\n",
    "            score_deque = deque(maxlen=100)\n",
    "            scores = []\n",
    "            current_episode = 1\n",
    "            if len(prev_score_data) !=0 :\n",
    "                current_episode = prev_score_data['current_episode']\n",
    "                scores = prev_score_data['scores']\n",
    "                for score in scores:\n",
    "                    score_deque.append(score)\n",
    "        \n",
    "        multiAgent = MADDPG(num_agents, state_size, action_size, params)\n",
    "        multiAgent.load_model(path=target_path)\n",
    "        \n",
    "    # If this is first time ; no previous saved model\n",
    "    else:\n",
    "        print('This is first time to run the model : {}'.format(model_name))\n",
    "        os.makedirs(target_path)\n",
    "        # Write parameters into json file\n",
    "        with open(target_path+'/params.json', 'w') as f:\n",
    "            json.dump(params, f)\n",
    "        with open(target_path+'/scores.json', 'w') as f:\n",
    "            json.dump({}, f)\n",
    "            \n",
    "        current_episode = 1\n",
    "        scores = []\n",
    "        score_deque = deque(maxlen=100)\n",
    "        multiAgent = MADDPG(num_agents, state_size, action_size, params)\n",
    "    \n",
    "    return multiAgent, scores, score_deque, current_episode, target_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is first time to run the model : model_18\n"
     ]
    }
   ],
   "source": [
    "maddpg, scores, score_deque, current_episode, target_path = set_up(model_name, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3.Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(num_episodes=2200, max_timestep=1000):\n",
    "    \n",
    "    for i in range(current_episode,num_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        # [num_agets, state_size]\n",
    "        states = env_info.vector_observations\n",
    "        agents_scores = np.zeros(num_agents)\n",
    "        \n",
    "        for t in range(max_timestep):\n",
    "            # [num_agents, action_size]\n",
    "            actions = maddpg.act(states)\n",
    "            \n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations\n",
    "            rewards = env_info.rewards\n",
    "            dones = env_info.local_done\n",
    "            rewards = env_info.rewards\n",
    "            \n",
    "            maddpg.step(states, actions, rewards, next_states, dones)\n",
    "            agents_scores += rewards\n",
    "            states = next_states\n",
    "            if np.any(dones):\n",
    "                break\n",
    "        # Episode score\n",
    "        episode_score = max(agents_scores)\n",
    "        score_deque.append(episode_score)\n",
    "        scores.append(episode_score)\n",
    "        \n",
    "        if i % CHECKPOINT_FREQ == 0 or i==num_episodes:\n",
    "            maddpg.save_model(target_path)\n",
    "            with open(target_path+'/scores.json', 'w') as f:\n",
    "                score_data = {'current_episode':i, 'scores': scores}\n",
    "                json.dump(score_data, f)\n",
    "                \n",
    "                \n",
    "        if (i% PRINT_EVERY) == 0:\n",
    "            print('Episode : {} \\t Current Score: {:.4f} \\t Average Score : {:.4f}'. format(i, episode_score, np.mean(score_deque)))\n",
    "            \n",
    "        if np.mean(score_deque) >= GOAL_AVG_SCORE:\n",
    "            print('The number of episodes needed to solve the problem : {}'.format(i))\n",
    "            print('Episode : {} \\t Current Score: {:.4f} \\t Average Score : {:.4f}'. format(i, episode_score, np.mean(score_deque)))\n",
    "            maddpg.save_model(target_path)\n",
    "            break\n",
    "            \n",
    "    return scores, maddpg.avg_actor_history, maddpg.avg_critic_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode : 50 \t Current Score: 0.0000 \t Average Score : 0.0040\n",
      "Episode : 100 \t Current Score: 0.0000 \t Average Score : 0.0020\n",
      "Episode : 150 \t Current Score: 0.0000 \t Average Score : 0.0000\n",
      "Episode : 200 \t Current Score: 0.0000 \t Average Score : 0.0000\n",
      "Episode : 250 \t Current Score: 0.0000 \t Average Score : 0.0000\n",
      "Episode : 300 \t Current Score: 0.0000 \t Average Score : 0.0000\n",
      "Episode : 350 \t Current Score: 0.0000 \t Average Score : 0.0000\n",
      "Episode : 400 \t Current Score: 0.0000 \t Average Score : 0.0000\n",
      "Episode : 450 \t Current Score: 0.0000 \t Average Score : 0.0000\n",
      "Episode : 500 \t Current Score: 0.0000 \t Average Score : 0.0000\n",
      "Episode : 550 \t Current Score: 0.0000 \t Average Score : 0.0000\n",
      "Episode : 600 \t Current Score: 0.0000 \t Average Score : 0.0009\n",
      "Episode : 650 \t Current Score: 0.0000 \t Average Score : 0.0054\n",
      "Episode : 700 \t Current Score: 0.0000 \t Average Score : 0.0109\n",
      "Episode : 750 \t Current Score: 0.0000 \t Average Score : 0.0109\n",
      "Episode : 800 \t Current Score: 0.0000 \t Average Score : 0.0090\n",
      "Episode : 850 \t Current Score: 0.0000 \t Average Score : 0.0162\n",
      "Episode : 900 \t Current Score: 0.0000 \t Average Score : 0.0173\n",
      "Episode : 950 \t Current Score: 0.0000 \t Average Score : 0.0191\n",
      "Episode : 1000 \t Current Score: 0.0000 \t Average Score : 0.0145\n",
      "Episode : 1050 \t Current Score: 0.0000 \t Average Score : 0.0046\n",
      "Episode : 1100 \t Current Score: 0.0900 \t Average Score : 0.0162\n",
      "Episode : 1150 \t Current Score: 0.0000 \t Average Score : 0.0320\n",
      "Episode : 1200 \t Current Score: 0.0000 \t Average Score : 0.0273\n",
      "Episode : 1250 \t Current Score: 0.1000 \t Average Score : 0.0384\n",
      "Episode : 1300 \t Current Score: 0.1000 \t Average Score : 0.0717\n",
      "Episode : 1350 \t Current Score: 0.0900 \t Average Score : 0.0897\n",
      "Episode : 1400 \t Current Score: 0.1000 \t Average Score : 0.0968\n",
      "Episode : 1450 \t Current Score: 0.1000 \t Average Score : 0.1063\n",
      "Episode : 1500 \t Current Score: 0.1000 \t Average Score : 0.1156\n",
      "Episode : 1550 \t Current Score: 0.0900 \t Average Score : 0.1079\n",
      "Episode : 1600 \t Current Score: 0.0900 \t Average Score : 0.1070\n",
      "Episode : 1650 \t Current Score: 0.1000 \t Average Score : 0.1197\n",
      "Episode : 1700 \t Current Score: 0.0900 \t Average Score : 0.1504\n",
      "Episode : 1750 \t Current Score: 0.0900 \t Average Score : 0.2940\n",
      "The number of episodes needed to solve the problem : 1762\n",
      "Episode : 1762 \t Current Score: 2.6000 \t Average Score : 0.5186\n"
     ]
    }
   ],
   "source": [
    "total_score, actor_loss, critic_loss = training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Plot of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(total_score)), total_score)\n",
    "plt.xlabel('# of episodes')\n",
    "plt.ylabel('Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAFZNJREFUeJzt3XmUXGWZx/HfU72ls9FZOhDSCZ1oBAMCCc0aRDZZEhRGGSe4ATqTM+OMB8XRATkDA25x46Aj6OSAjDpqRMAFEDFCOCCHxQ5LBBJIgABhS0PITtJLPfNH3e5Ud1d1V6e7+r4v+X7O6dP33nrr1lP33P71W+9dytxdAIB4ZNIuAAAwMAQ3AESG4AaAyBDcABAZghsAIkNwA0BkSg5uM6sws0fM7NZyFgQA6NtAetwXSFpZrkIAAKUpKbjNrEHSfEnXlrccAEB/Kktsd5WkL0kaU0rjiRMnemNj4+7WBAB7nOXLl7/u7vWltO03uM3sDEnr3X25mR3fR7uFkhZK0rRp09Tc3FxiuQAAM3u+1LalDJXMlfRBM1sraYmkE83s/3o2cvfF7t7k7k319SX90wAA7IZ+g9vdL3b3BndvlLRA0l3u/vGyVwYAKIjzuAEgMqUenJQkufvdku4uSyUAgJLQ4waAyBDcABAZghsAIhNccN+7ukUvvLE97TIAIFgDOjhZbtms6xPXPSRJWrtofsrVAECYgupx37Li5bRLAIDgBRXcS598Le0SACB4QQX3nSvXp10CAAQvqOB+q60j7RIAIHhBBTcAoH8ENwBEhuAGgMgQ3AAQGYIbACJDcANAZAhuAIgMwQ0AkSG4ASAyBDcARIbgBoDIENwAEBmCGwAiQ3ADQGSCDO6MpV0BAIQryOA++h0T0i4BAIIVZHADAIojuAEgMgQ3AESG4AaAyBDcABCZIIPbPe0KACBcBDcARCbM4BbJDQDFBBncWXIbAIoKMrjpcANAcUEGN0MlAFBcv8FtZiPM7CEze8zMnjCzy8tdFEMlAFBcZQltdko60d23mlmVpL+Y2e3u/kC5inJOKwGAovoNbs+l6NZktir5KWuyEtsAUFxJY9xmVmFmj0paL2mpuz9YjmJqqyokMVQCAH0pKbjdvcPdD5XUIOkIMzuoZxszW2hmzWbW3NLSMriqGCoBgKIGdFaJu2+UdLek0wo8ttjdm9y9qb6+flBFPbZu06CeDwBvZ6WcVVJvZnXJdK2kkyWtKndhAIDCSjmrZLKkn5hZhXJBf4O731resgAAxZRyVskKSbOHoRYAQAmCvHISAFAcwQ0AkSG4ASAyBDcARIbgBoDIENwAEJmggntkdUXaJQBA8IIK7uX/+f60SwCA4AUV3ACA/gUX3PvvPSbtEgAgaMEF91Ezxmuv2qq0ywCAYAUX3GbGV5cBQB+CC24AQN+CDG762wBQXHDB/di6jdqyoz3tMgAgWMEF9yMvbEy7BAAIWnDBDQDoG8ENAJEhuAEgMsEF9/lzG9MuAQCCFlxwj6quVMbSrgIAwhVccJtxHjcA9CW84JbEFe8AUFxwwS1jnAQA+hJccHfGNjeaAoDCggvuTNLjJrcBoLDggrtzpCRLcgNAQeEFd/Kb2AaAwsIL7iS56XADQGEBBncyxk2fGwAKCi64s9lcYNPjBoDCggvu7y59WpL0+tadKVcCAGEKLrg7bdjWmnYJABCkYIM7y1AJABQUbHB3kNwAUFCwwc0FOABQWL/BbWZTzWyZma00syfM7ILhKIweNwAUVllCm3ZJX3D3h81sjKTlZrbU3Z8sZ2FZghsACuq3x+3ur7j7w8n0FkkrJU0pd2HkNgAUNqAxbjNrlDRb0oMFHltoZs1m1tzS0jLowjoY4waAgkoObjMbLekmSZ9z9809H3f3xe7e5O5N9fX1gy6MoRIAKKyk4DazKuVC++fufnN5S8p5/KVNw/EyABCdUs4qMUnXSVrp7leWv6SczkvfAQDdldLjnivpE5JONLNHk595Za4LAFBEv6cDuvtftOv7DQAAKQv2ykkAQGEENwBEhuAGgMgQ3AAQGYIbACJDcANAZIIL7n3Gjki7BAAIWnDB/fGjpqVdAgAELbjgvuOJ19IuAQCCFlxwb29tT7sEAAhacMGdu6cVAKCY4II7Q24DQJ+CC+4tOxgqAYC+BBfck8bUpF0CAAQtuOCePW1c2iUAQNCCC+6mRoIbAPoSXHBXcFYJAPQpuODOcFoJAPQpvOCmxw0AfQouuCuCqwgAwhJcTNLjBoC+BRfcDeNGpl0CAAQtuOB+56TRaZcAAEELLrgBAH0juAEgMgQ3AESG4AaAyBDcABAZghsAIkNwA0BkCG4AiAzBDQCRCTq4N25vTbsEAAhO0MHd2pFNuwQACE7Qwf3mtra0SwCA4PQb3Gb2YzNbb2aPD0dB+ZY9tX64XxIAgldKj/t/JZ1W5joKWnT7qjReFgCC1m9wu/s9kjYMQy0AgBIEPcYNAOhtyILbzBaaWbOZNbe0tAzVagEAPQxZcLv7Yndvcvem+vr6oVotAKAHhkoAIDKlnA74S0n3S9rfzNaZ2afLXxYAoJjK/hq4+znDUQgAoDQMlQBAZAhuAIhMkMFtlnYFABCuIIN7Sl1t2iUAQLCCDO7LPnBg2iUAQLCCDO6DpoxNuwQACFaQwT15r11DJRu28S04AJAvyODOt6OtI+0SACAowQc3PW4A6C744M66p10CAAQl+OBubecLgwEgX/DB/eKb29MuAQCCEnxwP/Tcm2mXAABBCT64b13xctolAEBQgg/uLTva0y4BAIISfHADALoLNrgnjKpOuwQACFKwwb3giKlplwAAQQo2uA/YhxtNAUAhwQY3X6YAAIUFG9xc6Q4AhQUb3BNGc3ASAAoJNrgPbqhLuwQACFKwwT26pjLtEgAgSMEGNwCgsCiCe/3mHWmXAADBiCK4F/5sedolAEAwogjuR1/cmHYJABCMKIIbALALwQ0AkSG4ASAyBDcARIbgBoDIBB3cnz/5XV3Ta9ZvSbESAAhH0MG98LgZXdMnX3lPipUAQDiCDu6qitJuyu3uumDJI2q86Db93TX36Y2tOyVJ2ayrI8v9YQG8vZR0JyczO03S9yRVSLrW3ReVtapEZUX3/ys3LV+nDx/W0G1ZW0dWMy+5vWv+kRc26rCv/rlbm7nvnKDPnjhTU+pqVVtdoYmja8pXNACUWb89bjOrkHS1pNMlzZJ0jpnNKndhhfztpU3d5nuGdjH3rXlDCxY/oPd+a5mavvrnPq/EXL9lhxovuk3Ln98w6HoBoBxK6XEfIWmNuz8rSWa2RNKZkp4sZ2GFbNvZ3m2+lNAu5Kyr79PaRfMLPnbE1+6UJH34h/cXbZOGTdvbdMgVfxr0eg7YZ4z+4fCpmlJXq4ljalRbVaFR1ZWqH1OjTEba0ZrVK5vf0uMvbVZbR1Y/u/951VZXaMKoap1y4D46fv96jRlRqapMRmaS8R1zwLArJbinSHoxb36dpCPLU07fblnxsr7994dIkl7a+NaQr//3j73cbf7mh9fpQ3MairQeHlcvW6Nv3/HUkK1v1atbdPktu/c/909PvjZkdWDPMHPSaDU1jtfeY2s0bmS1Xtm0Q20dWTVOHCV318ENdarMmEZUVaimMqOsuzJJZ2DcqGq1d2TVnnW1d7g63DW6plKbtrdpZE2FJCljpoxJI6oq1NaRVW1VhVy5rz7MmFSRya2rrcN7HTMzM3nyHYmxdUBKCe5C76jXET8zWyhpoSRNmzZtkGXt8pGmBt3QvE6StKMt27V87qK7huw1JOmy3z2un9z/fLdlF97w2G4F9wPPvqED9hmjupGD+/q1xotuG9TzgbStXr9Vq9dvTbuMYTUcn9RLCe51kqbmzTdIerlnI3dfLGmxJDU1NQ3ZqRwXvn//ruAeKl+ed0CvZT1Du9N/37lanz1pZr/rdHdNv/gP3Zat+drpvQ6wluK1zTt05Nfv7LX81s8eq4Om7DXg9Q2HbNa1sz2rqgpTW4erpjKjTGbX/3zP+/bn9qyrMu+x1o6sKjMZued6VZ09rs4WlvSq3NW1zmI9pWzWtb2tQ6OqK9TW4XLl6spmXRUZ05Yd7XqrrUPrN+9UVYVp5atb9Oa2Vm3Y1qqOrOuuVevVsnWnZk4arRc2bNfE0TV67vVtvd7vfhNGatNbbaqrrdLaN7arYVytRlVXyiz3fqorMmrryKq1I6sXNwz9p0Ps2UoJ7r9Kmmlm0yW9JGmBpI+Wtao8++w1omv6nCNyPfl7V7f0aveLfzpS1yx7Rh89cpoObxyvjdtbNXPvMZKk9o6snnt9mybX1eqgy+7Qq5t2dntuW0e21/o6fXfp05qz3zgdPWOCMhnT61t36r41r+uCJY/q6a+erurKjLJZ14wv/6HXc995ye0675hG/dcHDyz5/bZ1ZHuF9qVnzNKnjp1e8jrSkMmYaqtzH18rK3o/nh+wPT+y1nQ9wfrcIfMzuthH20zGur72rrrSeqxfGjOiSpL0jvrRkqSmxvHdnv+VPl4fCIXl94SKNjKbJ+kq5U4H/LG7f62v9k1NTd7c3Dw0FUpa9epmnXbVvbrmY3M07z2TdcGSR/S7R3d1+u/8wvu6/hD7sr21XbMuvUNS948z0y++TSVshoJWXnGa3n3pH/ttN3mvEbrj88dpbBIcxfQcHvnNZ47R7Gnjdq84ANEws+Xu3lRK25I+x7v7H9z9Xe7+jv5Cuxwqkt5V58U0+aEtqaTQltT1ETxfe0e2V2jf8m/HllxbKaEtSa9s2qGD/+tPvXr3G7e3auvOdq1+bUuv0L7zC+8jtAH0EsVXqe9sz4XdXavW6wOH7NvtscsHMAyRLdCt7nngpG5kld7TUL5x5JmX3K7f/utcTRxdrWO/uaxou+vPO7zkf0gA9ixRBHfnwaHfPPKSLuhxoPDcYxpLXs+IAoOvp3/v3m7zj156iqTcUMrunNXx3DfmycyKjntLufPI+3PCAZMG/NoA9gxB36ukU/4ZCMd/5+7dXk8mY5pSV6uzDyt8it95Pf4JfOND7xnQ+q8///Cug2aZjGntovn64+feO+A6n/n6vAE/B8CeI4rgnjp+pCRpSl3toNfV2pHtGnrpqefZH+ccMU0/+Ojsktd9wv69e8kH7DNW93zxhJLXsXbR/K6LBgCgkCiCe9LY3E2hxozoPrLz638+esDratmyU7ckV0i25x0oPGXW3gXbn3HwvrryI4fo7MMadMbBkyVJy/79eD10yUnd2v35wuOKvua0CSP15BWn9lnXk1ecGtQl9gDCFcUY987kislVr3b/MoXDe5yDO1Ar8m5a9f1zivesPzSnoesKyh/kncG+dtF8tXVk1ZF1jagqcPJynpHVlVq7aL4WLL5fDzy7QUdOH6+Fx83QSe8u/A8DAIqJIrirduPqw1J88dePdU1X7+ZrVFVk1E9md7Nk4cA/JQBAviiGSqory1PmMy27LmXOMK4MIBJ7bHDvaOsY8nUCwHCIIrgrC/SGd3doo9NbrQQ3gDhFEdyFTo87dGrdoNb5Hzet6Jr+n08cNqh1AcBwiiO4C9xj5NrzSroXS1H5Xwrwfs7sABCRKIK70B08+7vL3kBwYBJATCIJboIVADpFEdwAgF32uOBu2o/7WwOIW5TB/cDFJ/XfqIhrPj6n2/zsaYM7OwUAhluUwd3zZlMDMWnMiG7z1593+GDLAYBhFWVwj6oZulus1I2sHrJ1AcBwiDK4AWBPtkcG9/lzGyVJXznroHQLAYDdEMVtXYfaZR84UBedfoBqCnwHJQCELroe96ePnT4k6yG0AcQqmuC+54sn6KxD99WX57077VIAIFXRDJVMmzBSVy0o/Yt7AeDtKpoeNwAgh+AGgMgQ3AAQGYIbACJDcANAZAhuAIgMwQ0AkSG4ASAy5u5Dv1KzFknP7+bTJ0p6fQjLeTtiG/WN7dM/tlH/hnsb7efu9aU0LEtwD4aZNbt7U9p1hIxt1De2T//YRv0LeRsxVAIAkSG4ASAyIQb34rQLiADbqG9sn/6xjfoX7DYKbowbANC3EHvcAIA+BBPcZnaamT1lZmvM7KK06yk3M5tqZsvMbKWZPWFmFyTLx5vZUjNbnfwelyw3M/t+sn1WmNmcvHWdm7RfbWbn5i0/zMz+ljzn+2Zmw/9OB8fMKszsETO7NZmfbmYPJu/1V2ZWnSyvSebXJI835q3j4mT5U2Z2at7y6Pc5M6szsxvNbFWyLx3NPtSdmX0++Rt73Mx+aWYjot+P3D31H0kVkp6RNENStaTHJM1Ku64yv+fJkuYk02MkPS1plqRvSbooWX6RpG8m0/Mk3S7JJB0l6cFk+XhJzya/xyXT45LHHpJ0dPKc2yWdnvb73o3tdKGkX0i6NZm/QdKCZPpHkv4lmf6MpB8l0wsk/SqZnpXsTzWSpif7WcXbZZ+T9BNJ/5hMV0uqYx/qtn2mSHpOUm3e/nNe7PtRKD3uIyStcfdn3b1V0hJJZ6ZcU1m5+yvu/nAyvUXSSuV2sjOV+2NU8vusZPpMST/1nAck1ZnZZEmnSlrq7hvc/U1JSyWdljw21t3v99ye99O8dUXBzBokzZd0bTJvkk6UdGPSpOf26dxuN0o6KWl/pqQl7r7T3Z+TtEa5/S36fc7Mxko6TtJ1kuTure6+UexDPVVKqjWzSkkjJb2iyPejUIJ7iqQX8+bXJcv2CMnHsdmSHpS0t7u/IuXCXdKkpFmxbdTX8nUFlsfkKklfkpRN5idI2uju7cl8/nvq2g7J45uS9gPdbjGZIalF0vXJcNK1ZjZK7ENd3P0lSd+R9IJygb1J0nJFvh+FEtyFxs32iNNdzGy0pJskfc7dN/fVtMAy343lUTCzMyStd/fl+YsLNPV+Hntbbp9EpaQ5kn7o7rMlbVNuaKSYPW4bJeP7Zyo3vLGvpFGSTi/QNKr9KJTgXidpat58g6SXU6pl2JhZlXKh/XN3vzlZ/FryEVXJ7/XJ8mLbqK/lDQWWx2KupA+a2VrlPn6eqFwPvC75yCt1f09d2yF5fC9JGzTw7RaTdZLWufuDyfyNygU5+9AuJ0t6zt1b3L1N0s2SjlHk+1Eowf1XSTOTI73Vyh0U+H3KNZVVMm52naSV7n5l3kO/l9R5VP9cSb/LW/7J5MyAoyRtSj4G3yHpFDMbl/QuTpF0R/LYFjM7KnmtT+atK3jufrG7N7h7o3L7w13u/jFJyySdnTTruX06t9vZSXtPli9IzhaYLmmmcgfcot/n3P1VSS+a2f7JopMkPSn2oXwvSDrKzEYm76FzG8W9H6V91LfzR7kj3k8rd4T2krTrGYb3e6xyH6lWSHo0+Zmn3HjanZJWJ7/HJ+1N0tXJ9vmbpKa8dX1KuYMlaySdn7e8SdLjyXN+oOSCq9h+JB2vXWeVzFDuD2aNpF9LqkmWj0jm1ySPz8h7/iXJNnhKeWdFvB32OUmHSmpO9qPfKndWCPtQ9210uaRVyfv4mXJnhkS9H3HlJABEJpShEgBAiQhuAIgMwQ0AkSG4ASAyBDcARIbgBoDIENwAEBmCGwAi8/+5NnOP9VSBGQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(actor_loss)), actor_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax=fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(critic_loss)), critic_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Watch the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weights from file\n",
    "multiAgent = MADDPG(num_agents, state_size, action_size, params)\n",
    "multiAgent.load_model(path=target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actor(\n",
       "  (bn1): BatchNorm1d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=24, out_features=96, bias=True)\n",
       "  (bn2): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=96, out_features=96, bias=True)\n",
       "  (bn3): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=96, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiAgent.agents_list[0].local_actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Critic(\n",
       "  (fc1): Linear(in_features=52, out_features=96, bias=True)\n",
       "  (fc2): Linear(in_features=96, out_features=96, bias=True)\n",
       "  (fc3): Linear(in_features=96, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiAgent.agents_list[0].local_critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Episode Score: 1.1000\n"
     ]
    }
   ],
   "source": [
    "scores = np.zeros(num_agents)\n",
    "env_info = env.reset(train_mode=False)[brain_name]\n",
    "state = env_info.vector_observations\n",
    "while True:\n",
    "    actions = multiAgent.act(states)\n",
    "            \n",
    "    env_info = env.step(actions)[brain_name]\n",
    "    next_states = env_info.vector_observations\n",
    "    rewards = env_info.rewards\n",
    "    dones = env_info.local_done\n",
    "    rewards = env_info.rewards\n",
    "\n",
    "    multiAgent.step(states, actions, rewards, next_states, dones)\n",
    "    scores += rewards\n",
    "    states = next_states\n",
    "    if np.any(dones):\n",
    "        break \n",
    "            \n",
    "episode_score = max(scores)\n",
    "print('Current Episode Score: {:.4f}'. format(episode_score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Future Works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though the problem can be solved by the current settings, It has several things to be imporved. First off, More fine-tuning hyper-paramters might be good start, but it could cost too much times. There are some ideas and I leave these investigations to future work.\n",
    "\n",
    "1. *Prioritized Experience Replay*\n",
    "\n",
    "    Current replay buffer samples the experience unfiormly. But certain experience might be more important than ohters. So by giving some probability based on priority to each experince, [Priortized Experience Replay buffer](https://arxiv.org/abs/1511.05952) can sample important expericens more frequently.\n",
    "    \n",
    "        \n",
    "2. *Applying Other Actor-Critic methods*\n",
    "    \n",
    "    There are many other actor-critic method such as TRPO(Trust Region Policy Optimization), TNPG(Truncated Natural Policy Gradient) which outperform the DDPG algorithm([Duan et al., Benchmarking Deep Reinforcement Learning for Continuous Control](https://arxiv.org/abs/1604.06778)). The current DDPG algorithm update actor network by using the policy gradient which depends on critic network. So the quality of critic learning procedure might impact the performance of actor network. There have been researches to improve critic learning procedure([Bellemare et al., A Distributional Perspective on Reinforcement Learning](https://arxiv.org/pdf/1707.06887.pdf)). [Barth-Maron et al.](http://arxiv.org/abs/1804.08617) proposed D4PG algorithm with several ideas such as modifying the training procedure and utilizing N-step returns. These works are candidates for the future works.\n",
    "    \n",
    "    \n",
    "3. *Other Normalization Techniques*\n",
    "\n",
    "    Current model only use batch normalization in actor network. I didn't use batch normalization layer in critic network because pytorch interprete 3D shape tensor input such as state tensor[batch_size, num_agents, state_size] in different way from what i expect. Pytorch has [other normalization layers](https://pytorch.org/docs/stable/nn.html#normalization-layers) like layer norm, instance norm, local reponse norm. These normalization layers might improve the training of networks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
